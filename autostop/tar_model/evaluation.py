# -*- coding: utf-8 -*-
"""evaluation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17qC0uOSU0kFcM2DG_1eYwsyhkj22XNLp
"""

# Commented out IPython magic to ensure Python compatibility.
import re
import os
import math
import sys
sys.path.append('..')
import numpy as np
import pandas as pd
pd.set_option('precision', 3)
import subprocess

from collections import  defaultdict
from operator import itemgetter
from scipy import interpolate

import matplotlib
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set_style("whitegrid")

#from autostop.utils import *

marker_dct = {0: u'tickleft', 1: u'tickright', 2: u'tickup', 3: u'tickdown', 4: u'caretleft', u'D': u'diamond', 
              6: u'caretup', 7: u'caretdown', u's': u'square', u'|': u'vline', None: u'nothing', u'None': u'nothing', 
              u'x': u'x', 5: u'caretright', u'_': u'hline', u'^': u'triangle_up', u' ': u'nothing', 
              u'd': u'thin_diamond', u'h': u'hexagon1', u'+': u'plus', u'*': u'star', u',': u'pixel', 
              u'o': u'circle', u'.': u'point', u'1': u'tri_down', u'p': u'pentagon', u'3': u'tri_left', 
              u'2': u'tri_up', u'4': u'tri_right', u'H': u'hexagon2', u'v': u'triangle_down', u'': u'nothing', 
              u'8': u'octagon', u'<': u'triangle_left', u'>': u'triangle_right'}

show_columns = ['recall', 'cost', 'reliability', 'loss_er', 're']

tar_master_dir = '/Users/danli/Documents/Project/autostop/autostop_project/tar-master'
datadir = '/Users/danli/Documents/Project/autostop/autostop_project/data'
retdir = '/Users/danli/Documents/Project/autostop/autostop_project/ret'
# figuredir = '/Users/danli/Documents/Project/autostop/autostop_project/figure'
paperfiguredir = '/Users/danli/Documents/GitProject/autostop/autostop/tois_paper/figures/'#'/Users/danli/Documents/'#



"""# Load Interaction result and TarRun result"""

def check_file(filepath):
    if not os.path.exists(filepath):
        print('not existing file {}'.format(filepath))
    if os.path.getsize(filepath) == 0:
        print('zero byte file {}'.format(filepath))

def get_model_name(model_name):
    model = model_name
    if 'random' in model_name:
        model = '0-random'
    if 'knee' in model_name:
        model = 'Knee'
    if 'scal' in model_name:
        model = 'SCAL'
    if 'target' in model_name:
        model ='Target'
    if 'sdtf' in model_name:
        model = 'SD-training'
    if 'sdfu' in model_name:
        model = 'SD-sampling'
    if 'autostop' in model_name:
        model = 'Ours'
    return model


def TarEvalResultReader(data_name, model_name, exp_id, train_test, topic_id):
    
    # run file
    runfile = os.path.join(retdir, data_name, 'tar_run', model_name, exp_id, train_test, topic_id + '.run')
    check_file(runfile)
    
    # qrel file
    qrelfile = os.path.join(datadir, data_name, 'abs_qrels', topic_id)
    check_file(qrelfile)
    
    # tar eval script
    script = os.path.join(tar_master_dir, 'scripts/tar_eval.py')
    
    # result
    ret = subprocess.check_output(['python', script, qrelfile, runfile])
    ret = subprocess.check_output([' tail -27 '], shell=True, input=ret)
    ret = ret.decode(encoding='utf-8')
   
    # dataframe
    dct = {}
    for line in ret.split('\n'):
      if line != '':
            tid, key, val = line.split()
            if tid == 'ALL':
                dct[key] = [float(val)]
    
    df = pd.DataFrame(dct)
    model = get_model_name(model_name)
    df['model_name'] = [model]
    df['exp_id'] = [exp_id]
    df['topic_id'] = [topic_id]
    df['recall'] = float(df['rels_found']) / float(df['num_rels'])
    df['cost'] = float(df['num_shown']) / float(df['num_docs'])
    return df


def InteractionLastResult(data_name, model_name, exp_id, train_test, topic_id):
    mdir = os.path.join(retdir, data_name, 'interaction', model_name, exp_id, train_test)
    filename = topic_id + '.csv'
    filepath = os.path.join(mdir, filename)
    
    check_file(filepath)
    model = get_model_name(model_name)
    
    df = pd.read_csv(filepath)
    df = df.iloc[-1:]  # last row
    df['model_name'] = [model]
    df['exp_id'] = [exp_id]
    df['topic_id'] = [topic_id]
    return df


def InteractionResultReader(data_name, model_name, exp_id, train_test, topic_id):
    mdir = os.path.join(retdir, data_name, 'interaction', model_name, exp_id, train_test)
    filename = topic_id + '.csv'
    filepath = os.path.join(mdir, filename)
    
    check_file(filepath)
    model = get_model_name(model_name)
    
    df = pd.read_csv(filepath)
    
    # construct new data
    startp, endp, nump = 0.1, 1.0, 10
    df = df.drop_duplicates(['sampled_num'])
    df['percentage'] = df['sampled_num'] / df['total_num']
    max_percentage = df['percentage'].max()
    min_percentage = df['percentage'].min()

    df['relative_error'] = np.abs(df['total_esti_r'] - df['total_true_r']) / df['total_true_r']
    df = df.fillna(0)

    x = np.linspace(startp, endp, nump)
    f = interpolate.InterpolatedUnivariateSpline(df['percentage'].values, df['relative_error'].values)
    relative_error = revised_f(x, f, min_percentage, max_percentage)
    f = interpolate.InterpolatedUnivariateSpline(df['percentage'].values, df['running_true_recall'].values)
    recall = revised_f(x, f, min_percentage, max_percentage)                                      
    f = interpolate.InterpolatedUnivariateSpline(df['percentage'].values, df['ap'].values)
    ap = revised_f(x, f, min_percentage, max_percentage)  
    
    df = pd.DataFrame({
                       'model_name': [model] * nump,
                        'exp_id': [exp_id] * nump,
                       'percentage': x, 
                       'relative_error': relative_error, 
                       'recall': recall,
                        'ap': ap})
    return df


def revised_f(x, f, min_percentage, max_percentage):
    y = []
    miny = f(min_percentage)
    maxy = f(max_percentage)
    for xi in x:
        if xi > max_percentage:
            y.append(maxy)
        elif xi < min_percentage:
            y.append(miny)
        else:
            y.append(f(xi))
    y = np.array(y)
    return y


def load_data(data_name, folders, exp_ids, topic_ids, func):
    dfs = []
    for folder in folders:
        for exp_id in exp_ids:
            for topic_id in topic_ids:
                try:
                    df = func(data_name, folder, exp_id, 'test', topic_id)
                    dfs.append(df)
                except Exception as e:
                    print(e,folder, exp_id, topic_id)
                    pass
    df = pd.concat(dfs, axis=0)
    return df

def pareto_frontier(Xs, Ys, maxX=True, maxY=True):
    '''
    Method to take two equally-sized lists and return just the elements which lie
    on the Pareto frontier, sorted into order.
    Default behaviour is to find the maximum for both X and Y, but the option is
    available to specify maxX = False or maxY = False to find the minimum for either
    or both of the parameters.
    '''

    # Sort the list in either ascending or descending order of X
    myList = sorted([[Xs[i], Ys[i]] for i in range(len(Xs))], reverse=maxX)
    # Start the Pareto frontier with the first value in the sorted list
    p_front = [myList[0]]
    # Loop through the sorted list
    for pair in myList[1:]:
        if maxY:
            if pair[1] >= p_front[-1][1]:  # Look for higher values of Y…
                p_front.append(pair)  # … and add them to the Pareto frontier
        else:
            if pair[1] <= p_front[-1][1]:  # Look for lower values of Y…
                p_front.append(pair)  # … and add them to the Pareto frontier
    # Turn resulting pairs back into a list of Xs and Ys
    p_frontX = [pair[0] for pair in p_front]
    p_frontY = [pair[1] for pair in p_front]
    return p_frontX, p_frontY

"""# AutoTAR"""

#dfs = []
#for topic_id in clef_2017_test_topics:
#    _df = TarEvalResultReader(data_name='clef2017', model_name='autotar_sp1.0_sr1.0_cttopicwise_md2_c1.0', exp_id='1', train_test='test', topic_id=topic_id)
#    dfs.append(_df)
#df = pd.concat(dfs, ignore_index=True)
#descdf = df[['wss_100', 'loss_er', 'norm_area', 'recall', 'cost', 'num_shown', 'num_docs', 'rels_found', 'num_rels', 'ap', 'NCG@10', 'NCG@100']]
#descdf.describe()





# dfs = []
# for topic_id in clef_2018_topics:
#     _df = TarEvalResultReader(data_name='clef2018', model_name='autotar_sp1.0_sr1.0_cttopicwise_md2_c1.0', exp_id='1', train_test='test', topic_id=topic_id)
#     dfs.append(_df)
# df = pd.concat(dfs, ignore_index=True)

# dfs = []
# for topic_id in clef_2019_topics:
#     _df = TarEvalResultReader(data_name='clef2019', model_name='autotar_sp1.0_sr1.0_cttopicwise_md2_c1.0', exp_id='1', train_test='test', topic_id=topic_id)
#     dfs.append(_df)
# df = pd.concat(dfs, ignore_index=True)

# dfs = []
# for topic_id in athome1_topics:
#     _df = TarEvalResultReader(data_name='athome1', model_name='autotar_sp0.5_sr1.0_cttopicwise_md2_c1.0', exp_id='1', train_test='test', topic_id=topic_id)
#     dfs.append(_df)
# df = pd.concat(dfs, ignore_index=True)
# df



"""# Knee"""

# dfs = []
# for topic_id in clef_2017_training_topics:
#     for rho in ['dynamic', 0.001,0.01, 0.1, 1, 2, 3, 6, 10]:
#         for beta in[100.0, 1000.0]:
#             _df = TarEvalResultReader(data_name='clef2017', model_name='knee_sb{}_sp1.0_sr1.0_rho{}_cttopicwise_md2_c1.0'.format(str(beta), str(rho)), exp_id='1', train_test='train', topic_id=topic_id)
#             _df['bound'] = rho
#             _df['beta'] = beta
#             dfs.append(_df)
# df = pd.concat(dfs, ignore_index=True)
# df = df.groupby(['bound', 'beta']).mean()
# df[['cost', 'recall','loss_er']]   # 'wss_100', 'loss_er', 'norm_area', 'recall', 'cost', 'total_cost', 'num_docs','ap'

dfs = []
clef_2017_test_topics = ["CD007394","CD007427"]
for topic_id in clef_2017_test_topics:
    for rho in ['dynamic']:
        for beta in[1000.0]:
            _df = TarEvalResultReader(data_name='clef2017', model_name='knee_sb{}_sp1.0_sr1.0_rho{}_cttopicwise_md2_c1.0'.format(str(beta), str(rho)), exp_id='1', train_test='test', topic_id=topic_id)
            _df['bound'] = rho
            _df['beta'] = beta
            dfs.append(_df)
df = pd.concat(dfs, ignore_index=True)
df = df.groupby(['bound', 'beta']).mean()

df[['cost', 'recall','loss_er']]

dfs = []
for topic_id in athome1_topics:
    for rho in ['dynamic']:
        for beta in[1000.0]:
            _df = TarEvalResultReader(data_name='athome1', model_name='knee_sb{}_sp1.0_sr1.0_rho{}_cttopicwise_md2_c1.0'.format(str(beta), str(rho)), exp_id='1', train_test='test', topic_id=topic_id)
            _df['bound'] = rho
            _df['beta'] = beta
            dfs.append(_df)
df = pd.concat(dfs, ignore_index=True)
# df = df.groupby(['bound', 'beta']).mean()

df[['cost', 'num_shown',  'recall','loss_er']]

